{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sentiment_ML.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yukamara/final_project/blob/main/Sentiment_ML.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2dogE5abD5dL",
        "outputId": "178dbdf6-5280-41b6-9b62-49e9858cbe7c"
      },
      "source": [
        "import pandas as pd \n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "# Find the latest version of spark 3.0  from http://www-us.apache.org/dist/spark/ and enter as the spark version\n",
        "# For example:\n",
        "# spark_version = 'spark-3.0.2'\n",
        "spark_version = 'spark-3.1.2'\n",
        "os.environ['SPARK_VERSION']=spark_version\n",
        "\n",
        "# Install Spark and Java\n",
        "!apt-get update\n",
        "!apt-get install openjdk-11-jdk-headless -qq > /dev/null\n",
        "!wget -q https://downloads.apache.org/spark/$SPARK_VERSION/$SPARK_VERSION-bin-hadoop2.7.tgz\n",
        "!tar xf $SPARK_VERSION-bin-hadoop2.7.tgz\n",
        "!pip install -q findspark\n",
        "\n",
        "# Set Environment Variables\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-11-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = f\"/content/{spark_version}-bin-hadoop2.7\"\n",
        "\n",
        "# Start a SparkSession\n",
        "import findspark\n",
        "findspark.init()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r0% [Working]\r            \rGet:1 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "\r0% [Connecting to archive.ubuntu.com (91.189.88.152)] [1 InRelease 14.2 kB/88.7\r0% [Waiting for headers] [Waiting for headers] [Waiting for headers] [Waiting f\r                                                                               \rHit:2 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease\n",
            "Ign:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Ign:4 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:5 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release\n",
            "Hit:6 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease\n",
            "Hit:7 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Hit:8 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Get:9 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "Hit:10 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Hit:11 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease\n",
            "Get:12 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
            "Hit:13 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Fetched 252 kB in 3s (94.8 kB/s)\n",
            "Reading package lists... Done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dryQCqTGEtip"
      },
      "source": [
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.appName(\"NaiveBayes\").getOrCreate()"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eyK_S93SFoV4",
        "outputId": "1450d192-29ad-4531-9a98-bc2ad636352d"
      },
      "source": [
        "# Read in data from S3 Buckets\n",
        "from pyspark import SparkFiles\n",
        "url =\"https://codingbootcamp2021104.s3.us-east-2.amazonaws.com/nlp_summary.csv\"\n",
        "spark.sparkContext.addFile(url)\n",
        "df = spark.read.csv(SparkFiles.get(\"nlp_summary.csv\"), sep=\",\", header=True)\n",
        "\n",
        "# Show DataFrame\n",
        "df.show()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---+--------------------+--------+\n",
            "|_c0|                text|   class|\n",
            "+---+--------------------+--------+\n",
            "|  0|Good Quality Dog ...|Positive|\n",
            "|  1|   Not as Advertised|Negative|\n",
            "|  2|\"\"\"Delight\"\" says...|Positive|\n",
            "|  3|      Cough Medicine|Negative|\n",
            "|  4|         Great taffy|Positive|\n",
            "|  5|          Nice Taffy|Positive|\n",
            "|  6|Great!  Just as g...|Positive|\n",
            "|  7|Wonderful, tasty ...|Positive|\n",
            "|  8|          Yay Barley|Positive|\n",
            "|  9|    Healthy Dog Food|Positive|\n",
            "| 10|The Best Hot Sauc...|Positive|\n",
            "| 11|\"My cats LOVE thi...|Positive|\n",
            "| 12|My Cats Are Not F...|Negative|\n",
            "| 13|   fresh and greasy!|Positive|\n",
            "| 14|Strawberry Twizzl...|Positive|\n",
            "| 15|Lots of twizzlers...|Positive|\n",
            "| 16|          poor taste|Negative|\n",
            "| 17|            Love it!|Positive|\n",
            "| 18|  GREAT SWEET CANDY!|Positive|\n",
            "| 19|Home delivered tw...|Positive|\n",
            "+---+--------------------+--------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "991CtJf1iHqJ",
        "outputId": "3fdf19a7-3a15-4828-95b0-ff3a0a614afd"
      },
      "source": [
        "df.na.drop()\n",
        "print((df.count(), len(df.columns)))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(925, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AEPyHbrGFBDQ",
        "outputId": "2ea5ef6f-257a-4d71-a90f-620f1b18dc2f"
      },
      "source": [
        "from pyspark.sql.functions import length\n",
        "# Create a length column to be used as a future feature \n",
        "data_df = df.withColumn('length', length(df['text']))\n",
        "data_df.show()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---+--------------------+--------+------+\n",
            "|_c0|                text|   class|length|\n",
            "+---+--------------------+--------+------+\n",
            "|  0|Good Quality Dog ...|Positive|    21|\n",
            "|  1|   Not as Advertised|Negative|    17|\n",
            "|  2|\"\"\"Delight\"\" says...|Positive|    25|\n",
            "|  3|      Cough Medicine|Negative|    14|\n",
            "|  4|         Great taffy|Positive|    11|\n",
            "|  5|          Nice Taffy|Positive|    10|\n",
            "|  6|Great!  Just as g...|Positive|    45|\n",
            "|  7|Wonderful, tasty ...|Positive|    22|\n",
            "|  8|          Yay Barley|Positive|    10|\n",
            "|  9|    Healthy Dog Food|Positive|    16|\n",
            "| 10|The Best Hot Sauc...|Positive|    31|\n",
            "| 11|\"My cats LOVE thi...|Positive|    64|\n",
            "| 12|My Cats Are Not F...|Negative|    36|\n",
            "| 13|   fresh and greasy!|Positive|    17|\n",
            "| 14|Strawberry Twizzl...|Positive|    28|\n",
            "| 15|Lots of twizzlers...|Positive|    40|\n",
            "| 16|          poor taste|Negative|    10|\n",
            "| 17|            Love it!|Positive|     8|\n",
            "| 18|  GREAT SWEET CANDY!|Positive|    18|\n",
            "| 19|Home delivered tw...|Positive|    23|\n",
            "+---+--------------------+--------+------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mCq4Tzu2FW01"
      },
      "source": [
        "from pyspark.ml.feature import Tokenizer, StopWordsRemover, HashingTF, IDF, StringIndexer\n",
        "# Create all the features to the data set\n",
        "pos_neg_to_num = StringIndexer(inputCol='class',outputCol='label')\n",
        "tokenizer = Tokenizer(inputCol=\"text\", outputCol=\"token_text\")\n",
        "stopremove = StopWordsRemover(inputCol='token_text',outputCol='stop_tokens')\n",
        "hashingTF = HashingTF(inputCol=\"stop_tokens\", outputCol='hash_token')\n",
        "idf = IDF(inputCol='hash_token', outputCol='idf_token')"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rF1oi-RGGjNn"
      },
      "source": [
        "from pyspark.ml.feature import VectorAssembler\n",
        "from pyspark.ml.linalg import Vector\n",
        "\n",
        "# Create feature vectors\n",
        "clean_up = VectorAssembler(inputCols=['idf_token', 'length'], outputCol='features')"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mn795S3sGkxk"
      },
      "source": [
        "# Create a and run a data processing Pipeline\n",
        "from pyspark.ml import Pipeline\n",
        "data_prep_pipeline = Pipeline(stages=[pos_neg_to_num, tokenizer, stopremove, hashingTF, idf, clean_up])"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dfbhe56cGl-c"
      },
      "source": [
        "# Fit and transform the pipeline\n",
        "cleaner = data_prep_pipeline.fit(data_df)\n",
        "cleaned = cleaner.transform(data_df)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9r5QWTapGnHu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f011d73d-68b7-479b-be9d-1ea073a240ca"
      },
      "source": [
        "\n",
        " # Show label and resulting features\n",
        "cleaned.select(['label', 'features']).show()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-----+--------------------+\n",
            "|label|            features|\n",
            "+-----+--------------------+\n",
            "|  0.0|(262145,[43890,54...|\n",
            "|  1.0|(262145,[187033,2...|\n",
            "|  0.0|(262145,[10804,11...|\n",
            "|  1.0|(262145,[194543,2...|\n",
            "|  0.0|(262145,[107062,2...|\n",
            "|  0.0|(262145,[22346,10...|\n",
            "|  0.0|(262145,[19352,11...|\n",
            "|  0.0|(262145,[107062,1...|\n",
            "|  0.0|(262145,[14914,47...|\n",
            "|  0.0|(262145,[54556,12...|\n",
            "|  0.0|(262145,[47197,60...|\n",
            "|  0.0|(262145,[31739,48...|\n",
            "|  1.0|(262145,[89833,11...|\n",
            "|  0.0|(262145,[210587,2...|\n",
            "|  0.0|(262145,[33793,38...|\n",
            "|  0.0|(262145,[53803,72...|\n",
            "|  1.0|(262145,[85735,22...|\n",
            "|  0.0|(262145,[90225,18...|\n",
            "|  0.0|(262145,[48167,15...|\n",
            "|  0.0|(262145,[17893,11...|\n",
            "+-----+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4fw-PxwSOUxB"
      },
      "source": [
        "from pyspark.ml.classification import NaiveBayes\n",
        "# Break data down into a training set and a testing set\n",
        "training, testing = cleaned.randomSplit([0.7, 0.3])\n",
        "\n",
        "# Create a Naive Bayes model and fit training data\n",
        "nb = NaiveBayes()\n",
        "predictor = nb.fit(training)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nqA5XbKz61HU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d861abdf-0daf-4265-8108-f344928690b2"
      },
      "source": [
        " # Tranform the model with the testing data\n",
        "test_results = predictor.transform(testing)\n",
        "test_results.show(10)\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---+--------------------+--------+------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
            "|_c0|                text|   class|length|label|          token_text|         stop_tokens|          hash_token|           idf_token|            features|       rawPrediction|         probability|prediction|\n",
            "+---+--------------------+--------+------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
            "|100|Taste wise it is ...|Positive|    30|  0.0|[taste, wise, it,...|[taste, wise, 6, ...|(262144,[93086,12...|(262144,[93086,12...|(262145,[93086,12...|[-406.45012199212...|[1.0,5.7337242376...|       0.0|\n",
            "|101|       Great Support|Positive|    13|  0.0|    [great, support]|    [great, support]|(262144,[177817,2...|(262144,[177817,2...|(262145,[177817,2...|[-133.60457804497...|[0.99999999999995...|       0.0|\n",
            "|102|               TART!|Positive|     5|  0.0|             [tart!]|             [tart!]|(262144,[247468],...|(262144,[247468],...|(262145,[247468,2...|[-93.006806633297...|[0.99992681444867...|       0.0|\n",
            "|104|Loved these Tartlets|Positive|    20|  0.0|[loved, these, ta...|   [loved, tartlets]|(262144,[216221,2...|(262144,[216221,2...|(262145,[216221,2...|[-175.54052103237...|[1.0,1.9501146981...|       0.0|\n",
            "|113|the best tea ever...|Positive|    39|  0.0|[the, best, tea, ...|[best, tea, ever....|(262144,[36797,44...|(262144,[36797,44...|(262145,[36797,44...|[-461.04174611517...|[1.0,2.6634813463...|       0.0|\n",
            "|115|       Wonderful Tea|Positive|    13|  0.0|    [wonderful, tea]|    [wonderful, tea]|(262144,[15585,36...|(262144,[15585,36...|(262145,[15585,36...|[-123.30914778446...|[1.0,1.8203229402...|       0.0|\n",
            "|116|       Great cookies|Positive|    13|  0.0|    [great, cookies]|    [great, cookies]|(262144,[14940,26...|(262144,[14940,26...|(262145,[14940,26...|[-117.58557354979...|[1.0,7.5713681906...|       0.0|\n",
            "|119|       Best Cat Food|Positive|    13|  0.0|   [best, cat, food]|   [best, cat, food]|(262144,[121133,1...|(262144,[121133,1...|(262145,[121133,1...|[-147.13751063570...|[1.0,1.3689909707...|       0.0|\n",
            "| 12|My Cats Are Not F...|Negative|    36|  1.0|[my, cats, are, n...|[cats, fans, new,...|(262144,[89833,11...|(262144,[89833,11...|(262145,[89833,11...|[-306.26011869704...|[1.0,1.1912996813...|       0.0|\n",
            "|120|         Great food.|Positive|    11|  0.0|      [great, food.]|      [great, food.]|(262144,[177381,2...|(262144,[177381,2...|(262145,[177381,2...|[-105.10275007284...|[1.0,1.5473590334...|       0.0|\n",
            "+---+--------------------+--------+------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
            "only showing top 10 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Jq8tR2MAnjt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "202b3504-b45c-40a4-922b-d920e03120d6"
      },
      "source": [
        "from pyspark.sql.functions import countDistinct\n",
        "df2=test_results.select(countDistinct(\"prediction\"))\n",
        "\n",
        "df2.show()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------------------+\n",
            "|count(DISTINCT prediction)|\n",
            "+--------------------------+\n",
            "|                         2|\n",
            "+--------------------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DxU5DWjy6298",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a5f253e-4ece-435d-e7f4-3ffb73c3b576"
      },
      "source": [
        " # Use the Class Evaluator for a cleaner description\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "\n",
        "acc_eval = MulticlassClassificationEvaluator()\n",
        "acc = acc_eval.evaluate(test_results)\n",
        "print(\"Accuracy of model at predicting reviews was: %f\" % acc)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of model at predicting reviews was: 0.775230\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vtkEchKD7U5u"
      },
      "source": [
        "test_results_pd = test_results.toPandas()"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xiELgqolASlZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f8d00763-2573-4fae-8d68-e5b39e54e983"
      },
      "source": [
        "test_results_pd['prediction'].value_counts()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0    293\n",
              "1.0      1\n",
              "Name: prediction, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wpZUsPx6Lic-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "97af4455-732c-46ee-cfcd-671b36e33c95"
      },
      "source": [
        "test_results_pd['label'].value_counts()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0    247\n",
              "1.0     47\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CECHv_glLryH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "e9aa7e84-d384-489e-93cd-ea4a14dffe88"
      },
      "source": [
        "#Place Holder for graph 1 \n",
        "fig1 = test_results_pd['prediction'].hist()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bDC7LF0Ei5H5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "outputId": "9f46ec1e-8eeb-40c8-9b9d-a87ea1078bc3"
      },
      "source": [
        "# Sample Image until graph1 is complete\n",
        "fig1.savefig('fig1.pdf')"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-17e03afdd181>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Sample Image until graph1 is complete\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mfig1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msavefig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'fig1.pdf'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: 'AxesSubplot' object has no attribute 'savefig'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZiIg2CEyMr9z"
      },
      "source": [
        "#Place Holder for graph 1 \n",
        "fig2 = test_results_pd['label'].hist()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WsojC9u5i6Gs"
      },
      "source": [
        "# Sample Image until graph2 is complete\n",
        "fig2.savefig('fig2.pdf')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sentiment_ML.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yukamara/final_project/blob/main/Sentiment_ML.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2dogE5abD5dL",
        "outputId": "33f5cfe6-8bf7-49fd-f91a-241247c6fd43"
      },
      "source": [
        "import pandas as pd \n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "# Find the latest version of spark 3.0  from http://www-us.apache.org/dist/spark/ and enter as the spark version\n",
        "# For example:\n",
        "# spark_version = 'spark-3.0.2'\n",
        "spark_version = 'spark-3.1.2'\n",
        "os.environ['SPARK_VERSION']=spark_version\n",
        "\n",
        "# Install Spark and Java\n",
        "!apt-get update\n",
        "!apt-get install openjdk-11-jdk-headless -qq > /dev/null\n",
        "!wget -q https://downloads.apache.org/spark/$SPARK_VERSION/$SPARK_VERSION-bin-hadoop2.7.tgz\n",
        "!tar xf $SPARK_VERSION-bin-hadoop2.7.tgz\n",
        "!pip install -q findspark\n",
        "\n",
        "# Set Environment Variables\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-11-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = f\"/content/{spark_version}-bin-hadoop2.7\"\n",
        "\n",
        "# Start a SparkSession\n",
        "import findspark\n",
        "findspark.init()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rGet:1 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "Ign:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:3 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease\n",
            "Ign:4 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:5 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release\n",
            "Hit:6 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Get:7 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease [3,626 B]\n",
            "Hit:8 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Get:9 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "Hit:10 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Hit:11 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease\n",
            "Get:12 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [1,426 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
            "Get:14 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease [21.3 kB]\n",
            "Get:16 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [2,295 kB]\n",
            "Get:17 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ Packages [67.0 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [2,731 kB]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [2,200 kB]\n",
            "Get:21 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic/main amd64 Packages [41.6 kB]\n",
            "Fetched 9,038 kB in 5s (1,996 kB/s)\n",
            "Reading package lists... Done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dryQCqTGEtip"
      },
      "source": [
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.appName(\"NaiveBayes\").getOrCreate()"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eyK_S93SFoV4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fbe2de9e-969e-4e12-efa0-a2d035c92695"
      },
      "source": [
        "# Read in data from S3 Buckets\n",
        "from pyspark import SparkFiles\n",
        "url =\"https://codingbootcamp2021104.s3.us-east-2.amazonaws.com/nlp_summary.csv\"\n",
        "spark.sparkContext.addFile(url)\n",
        "df = spark.read.csv(SparkFiles.get(\"nlp_summary.csv\"), sep=\",\", header=True)\n",
        "\n",
        "# Show DataFrame\n",
        "df.show()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+--------------------+--------+\n",
            "|_c0|                text|   class|\n",
            "+---+--------------------+--------+\n",
            "|  0|Good Quality Dog ...|Positive|\n",
            "|  1|   Not as Advertised|Negative|\n",
            "|  2|\"\"\"Delight\"\" says...|Positive|\n",
            "|  3|      Cough Medicine|Negative|\n",
            "|  4|         Great taffy|Positive|\n",
            "|  5|          Nice Taffy|Positive|\n",
            "|  6|Great!  Just as g...|Positive|\n",
            "|  7|Wonderful, tasty ...|Positive|\n",
            "|  8|          Yay Barley|Positive|\n",
            "|  9|    Healthy Dog Food|Positive|\n",
            "| 10|The Best Hot Sauc...|Positive|\n",
            "| 11|\"My cats LOVE thi...|Positive|\n",
            "| 12|My Cats Are Not F...|Negative|\n",
            "| 13|   fresh and greasy!|Positive|\n",
            "| 14|Strawberry Twizzl...|Positive|\n",
            "| 15|Lots of twizzlers...|Positive|\n",
            "| 16|          poor taste|Negative|\n",
            "| 17|            Love it!|Positive|\n",
            "| 18|  GREAT SWEET CANDY!|Positive|\n",
            "| 19|Home delivered tw...|Positive|\n",
            "+---+--------------------+--------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "991CtJf1iHqJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "85f83d50-02ad-4c63-b185-fabd0367f221"
      },
      "source": [
        "df.na.drop()\n",
        "print((df.count(), len(df.columns)))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(925, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AEPyHbrGFBDQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1456bc7f-9c00-4503-afed-28b1d9760ebf"
      },
      "source": [
        "from pyspark.sql.functions import length\n",
        "# Create a length column to be used as a future feature \n",
        "data_df = df.withColumn('length', length(df['text']))\n",
        "data_df.show()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+--------------------+--------+------+\n",
            "|_c0|                text|   class|length|\n",
            "+---+--------------------+--------+------+\n",
            "|  0|Good Quality Dog ...|Positive|    21|\n",
            "|  1|   Not as Advertised|Negative|    17|\n",
            "|  2|\"\"\"Delight\"\" says...|Positive|    25|\n",
            "|  3|      Cough Medicine|Negative|    14|\n",
            "|  4|         Great taffy|Positive|    11|\n",
            "|  5|          Nice Taffy|Positive|    10|\n",
            "|  6|Great!  Just as g...|Positive|    45|\n",
            "|  7|Wonderful, tasty ...|Positive|    22|\n",
            "|  8|          Yay Barley|Positive|    10|\n",
            "|  9|    Healthy Dog Food|Positive|    16|\n",
            "| 10|The Best Hot Sauc...|Positive|    31|\n",
            "| 11|\"My cats LOVE thi...|Positive|    64|\n",
            "| 12|My Cats Are Not F...|Negative|    36|\n",
            "| 13|   fresh and greasy!|Positive|    17|\n",
            "| 14|Strawberry Twizzl...|Positive|    28|\n",
            "| 15|Lots of twizzlers...|Positive|    40|\n",
            "| 16|          poor taste|Negative|    10|\n",
            "| 17|            Love it!|Positive|     8|\n",
            "| 18|  GREAT SWEET CANDY!|Positive|    18|\n",
            "| 19|Home delivered tw...|Positive|    23|\n",
            "+---+--------------------+--------+------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mCq4Tzu2FW01"
      },
      "source": [
        "from pyspark.ml.feature import Tokenizer, StopWordsRemover, HashingTF, IDF, StringIndexer\n",
        "# Create all the features to the data set\n",
        "pos_neg_to_num = StringIndexer(inputCol='class',outputCol='label')\n",
        "tokenizer = Tokenizer(inputCol=\"text\", outputCol=\"token_text\")\n",
        "stopremove = StopWordsRemover(inputCol='token_text',outputCol='stop_tokens')\n",
        "hashingTF = HashingTF(inputCol=\"stop_tokens\", outputCol='hash_token')\n",
        "idf = IDF(inputCol='hash_token', outputCol='idf_token')"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rF1oi-RGGjNn"
      },
      "source": [
        "from pyspark.ml.feature import VectorAssembler\n",
        "from pyspark.ml.linalg import Vector\n",
        "\n",
        "# Create feature vectors\n",
        "clean_up = VectorAssembler(inputCols=['idf_token', 'length'], outputCol='features')"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mn795S3sGkxk"
      },
      "source": [
        "# Create a and run a data processing Pipeline\n",
        "from pyspark.ml import Pipeline\n",
        "data_prep_pipeline = Pipeline(stages=[pos_neg_to_num, tokenizer, stopremove, hashingTF, idf, clean_up])"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dfbhe56cGl-c"
      },
      "source": [
        "# Fit and transform the pipeline\n",
        "cleaner = data_prep_pipeline.fit(data_df)\n",
        "cleaned = cleaner.transform(data_df)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9r5QWTapGnHu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "35a555d6-4593-404e-a2c2-754a9c12b19e"
      },
      "source": [
        "\n",
        " # Show label and resulting features\n",
        "cleaned.select(['label', 'features']).show()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+--------------------+\n",
            "|label|            features|\n",
            "+-----+--------------------+\n",
            "|  0.0|(262145,[43890,54...|\n",
            "|  1.0|(262145,[187033,2...|\n",
            "|  0.0|(262145,[10804,11...|\n",
            "|  1.0|(262145,[194543,2...|\n",
            "|  0.0|(262145,[107062,2...|\n",
            "|  0.0|(262145,[22346,10...|\n",
            "|  0.0|(262145,[19352,11...|\n",
            "|  0.0|(262145,[107062,1...|\n",
            "|  0.0|(262145,[14914,47...|\n",
            "|  0.0|(262145,[54556,12...|\n",
            "|  0.0|(262145,[47197,60...|\n",
            "|  0.0|(262145,[31739,48...|\n",
            "|  1.0|(262145,[89833,11...|\n",
            "|  0.0|(262145,[210587,2...|\n",
            "|  0.0|(262145,[33793,38...|\n",
            "|  0.0|(262145,[53803,72...|\n",
            "|  1.0|(262145,[85735,22...|\n",
            "|  0.0|(262145,[90225,18...|\n",
            "|  0.0|(262145,[48167,15...|\n",
            "|  0.0|(262145,[17893,11...|\n",
            "+-----+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4fw-PxwSOUxB"
      },
      "source": [
        "from pyspark.ml.classification import NaiveBayes\n",
        "# Break data down into a training set and a testing set\n",
        "training, testing = cleaned.randomSplit([0.7, 0.3])\n",
        "\n",
        "# Create a Naive Bayes model and fit training data\n",
        "nb = NaiveBayes()\n",
        "predictor = nb.fit(training)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nqA5XbKz61HU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae05845d-b907-4380-eb10-9fc38b26eb39"
      },
      "source": [
        " # Tranform the model with the testing data\n",
        "test_results = predictor.transform(testing)\n",
        "test_results.show(10)\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+--------------------+--------+------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
            "|_c0|                text|   class|length|label|          token_text|         stop_tokens|          hash_token|           idf_token|            features|       rawPrediction|         probability|prediction|\n",
            "+---+--------------------+--------+------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
            "| 10|The Best Hot Sauc...|Positive|    31|  0.0|[the, best, hot, ...|[best, hot, sauce...|(262144,[47197,60...|(262144,[47197,60...|(262145,[47197,60...|[-266.05750194129...|[1.0,3.6864365064...|       0.0|\n",
            "|103|Omaha Apple Tartlets|Positive|    20|  0.0|[omaha, apple, ta...|[omaha, apple, ta...|(262144,[171740,2...|(262144,[171740,2...|(262145,[171740,2...|[-278.13136317112...|[1.0,2.1257128886...|       0.0|\n",
            "|105|            The best|Positive|     8|  0.0|         [the, best]|              [best]|(262144,[166027],...|(262144,[166027],...|(262145,[166027,2...|[-45.025568100376...|[0.99999999999466...|       0.0|\n",
            "|108|     Asparagus Bliss|Positive|    15|  0.0|  [asparagus, bliss]|  [asparagus, bliss]|(262144,[8402,237...|(262144,[8402,237...|(262145,[8402,237...|[-201.40011046254...|[0.99999999997799...|       0.0|\n",
            "|109|My Idea of a Good...|Positive|    28|  0.0|[my, idea, of, a,...|[idea, good, diet...|(262144,[113432,1...|(262144,[113432,1...|(262145,[113432,1...|[-305.73571790575...|[1.0,1.3582050779...|       0.0|\n",
            "|110|Low Carb Angel Fo...|Negative|    25|  1.0|[low, carb, angel...|[low, carb, angel...|(262144,[38270,55...|(262144,[38270,55...|(262145,[38270,55...|[-385.19150691317...|[1.0,1.0913661799...|       0.0|\n",
            "|113|the best tea ever...|Positive|    39|  0.0|[the, best, tea, ...|[best, tea, ever....|(262144,[36797,44...|(262144,[36797,44...|(262145,[36797,44...|[-460.65138759192...|[1.0,1.1405492083...|       0.0|\n",
            "|114|          Tea review|Positive|    10|  0.0|       [tea, review]|       [tea, review]|(262144,[36797,17...|(262144,[36797,17...|(262145,[36797,17...|[-118.67844160643...|[0.99999999999999...|       0.0|\n",
            "|117|Best everyday coo...|Positive|    21|  0.0|[best, everyday, ...|[best, everyday, ...|(262144,[166027,1...|(262144,[166027,1...|(262145,[166027,1...|[-217.78417374718...|[1.0,1.9623090058...|       0.0|\n",
            "|119|       Best Cat Food|Positive|    13|  0.0|   [best, cat, food]|   [best, cat, food]|(262144,[121133,1...|(262144,[121133,1...|(262145,[121133,1...|[-143.81979765655...|[1.0,4.0973681471...|       0.0|\n",
            "+---+--------------------+--------+------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Jq8tR2MAnjt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ecf9e51-176e-4119-9398-3fea321e414b"
      },
      "source": [
        "from pyspark.sql.functions import countDistinct\n",
        "df2=test_results.select(countDistinct(\"prediction\"))\n",
        "\n",
        "df2.show()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------------+\n",
            "|count(DISTINCT prediction)|\n",
            "+--------------------------+\n",
            "|                         2|\n",
            "+--------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DxU5DWjy6298",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "406d64d8-a06a-4504-f54f-552c01fb967f"
      },
      "source": [
        " # Use the Class Evaluator for a cleaner description\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "\n",
        "acc_eval = MulticlassClassificationEvaluator()\n",
        "acc = acc_eval.evaluate(test_results)\n",
        "print(\"Accuracy of model at predicting reviews was: %f\" % acc)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of model at predicting reviews was: 0.777585\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vtkEchKD7U5u"
      },
      "source": [
        "test_results_pd = test_results.toPandas()"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xiELgqolASlZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a265350d-b759-4a58-d21a-3c4596d7890e"
      },
      "source": [
        "test_results_pd['prediction'].value_counts()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0    270\n",
              "1.0      1\n",
              "Name: prediction, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wpZUsPx6Lic-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ca504a3-0ec5-48a0-fb99-9132047f21b5"
      },
      "source": [
        "test_results_pd['label'].value_counts()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0    228\n",
              "1.0     43\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CECHv_glLryH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 387
        },
        "outputId": "a49900b3-34cd-4db1-89c5-87508c9060f3"
      },
      "source": [
        ""
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "        <script type=\"text/javascript\">\n",
              "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
              "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
              "        if (typeof require !== 'undefined') {\n",
              "        require.undef(\"plotly\");\n",
              "        requirejs.config({\n",
              "            paths: {\n",
              "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
              "            }\n",
              "        });\n",
              "        require(['plotly'], function(Plotly) {\n",
              "            window._Plotly = Plotly;\n",
              "        });\n",
              "        }\n",
              "        </script>\n",
              "        "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-a0d77bf42acb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistogram\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_results_pd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Score\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m fig.update_traces(marker_color=\"turquoise\",marker_line_color='rgb(8,48,107)',\n\u001b[1;32m     11\u001b[0m                   marker_line_width=1.5)\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/plotly/express/_chart_types.py\u001b[0m in \u001b[0;36mhistogram\u001b[0;34m(data_frame, x, y, color, facet_row, facet_col, facet_col_wrap, hover_name, hover_data, animation_frame, animation_group, category_orders, labels, color_discrete_sequence, color_discrete_map, marginal, opacity, orientation, barmode, barnorm, histnorm, log_x, log_y, range_x, range_y, histfunc, cumulative, nbins, title, template, width, height)\u001b[0m\n\u001b[1;32m    370\u001b[0m             \u001b[0mbingroup\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"x\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0morientation\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"v\"\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"y\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    371\u001b[0m         ),\n\u001b[0;32m--> 372\u001b[0;31m         \u001b[0mlayout_patch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbarmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbarmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbarnorm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbarnorm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    373\u001b[0m     )\n\u001b[1;32m    374\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/plotly/express/_core.py\u001b[0m in \u001b[0;36mmake_figure\u001b[0;34m(args, constructor, trace_patch, layout_patch)\u001b[0m\n\u001b[1;32m   1170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1171\u001b[0m     args, trace_specs, grouped_mappings, sizeref, show_colorbar = infer_config(\n\u001b[0;32m-> 1172\u001b[0;31m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconstructor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrace_patch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1173\u001b[0m     )\n\u001b[1;32m   1174\u001b[0m     \u001b[0mgrouper\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrouper\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mone_group\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgrouped_mappings\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mone_group\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/plotly/express/_core.py\u001b[0m in \u001b[0;36minfer_config\u001b[0;34m(args, constructor, trace_patch)\u001b[0m\n\u001b[1;32m   1026\u001b[0m             \u001b[0mall_attrables\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mgroup_attr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1028\u001b[0;31m     \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_dataframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_attrables\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marray_attrables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1029\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1030\u001b[0m     \u001b[0mattrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mattrables\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/plotly/express/_core.py\u001b[0m in \u001b[0;36mbuild_dataframe\u001b[0;34m(args, attrables, array_attrables)\u001b[0m\n\u001b[1;32m    944\u001b[0m                             \u001b[0;34m\"\\n To use the index, pass it in directly as `df.index`.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    945\u001b[0m                         )\n\u001b[0;32m--> 946\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    947\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlength\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_input\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0margument\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlength\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    948\u001b[0m                     raise ValueError(\n",
            "\u001b[0;31mValueError\u001b[0m: Value of 'x' is not the name of a column in 'data_frame'. Expected one of ['_c0', 'text', 'class', 'length', 'label', 'token_text', 'stop_tokens', 'hash_token', 'idf_token', 'features', 'rawPrediction', 'probability', 'prediction'] but received: Score"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bDC7LF0Ei5H5"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZiIg2CEyMr9z"
      },
      "source": [
        "#"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WsojC9u5i6Gs"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xFSepOkJsHx_"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}